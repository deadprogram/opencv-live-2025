[main]
logging = "info"
destination = ":8080"
cuda-enable = true

[processing]
pipeline = [
    "ollama.wasm",
    "style-transfer.wasm",
    "captions.wasm"
]

[configuration]
ollama-model = "qnguyen3/nanollava"
caption-line-height = "30"
caption-size = "0.9"

[models]
download = true

[server]
mcp-enable = false
mcp-port = ":5001"
